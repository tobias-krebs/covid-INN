{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from FrEIA.framework import *\n",
    "from FrEIA.modules import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 Entries\n",
      "Loaded 2000 Entries\n",
      "Loaded 3000 Entries\n",
      "Loaded 4000 Entries\n",
      "Loaded 5000 Entries\n",
      "Loaded 6000 Entries\n",
      "Loaded 7000 Entries\n",
      "Loaded 8000 Entries\n",
      "Loaded 9000 Entries\n",
      "Loaded 10000 Entries\n"
     ]
    }
   ],
   "source": [
    "def load_data(num):\n",
    "    all_data = []\n",
    "    all_params = []\n",
    "    all_length = []\n",
    "    i = 0\n",
    "    j = 2\n",
    "    while(len(all_data)<num):\n",
    "        name_dat = f\"./data{j}/dat{i}.csv\"\n",
    "        name_param = f\"./params{j}/params{i}.csv\"\n",
    "        try:\n",
    "            df_dat = pd.read_csv(name_dat)\n",
    "            df_param = pd.read_csv(name_param)\n",
    "            param = df_param.to_numpy()[0,[0,3,4,5,6,7,8]]\n",
    "            data = df_dat.iloc[:,2].to_numpy().reshape(-1,7)\n",
    "            if len(data[np.isnan(data)]) == 0:\n",
    "                all_data.append(torch.from_numpy(data).to(torch.float32).to(device))\n",
    "                all_params.append(param)\n",
    "                all_length.append(len(data))\n",
    "            i += 1\n",
    "        except:\n",
    "            i = 0\n",
    "            j += 1\n",
    "        if j>8:\n",
    "            print(\"not so much data\")\n",
    "            break\n",
    "        if len(all_data)%1000 == 0:\n",
    "            print(\"Loaded\",len(all_data),\"Entries\")\n",
    "    all_data = nn.utils.rnn.pad_sequence(all_data, batch_first = True).to(device).to(torch.float32)\n",
    "    all_params = torch.from_numpy(np.array(all_params)).to(torch.float32).to(device)\n",
    "    return all_data, all_params, all_length\n",
    "data, params, length = load_data(10000)\n",
    "\n",
    "means = params.mean(dim = 0)\n",
    "stds = params.std(dim = 0)\n",
    "stds[stds==0] = 1\n",
    "params_normalized = (params-means)/stds\n",
    "\n",
    "boarder = max(params_normalized.max(),-params_normalized.min())\n",
    "maximal = boarder.item()+1e-6\n",
    "params_pre = torch.arctanh(params_normalized/maximal) #get this from [-1.8,1.8] to (-infty, infty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_subnet(N, inp_size, hidden_size, out_size):\n",
    "    layer_list = []\n",
    "    layer_list.append(nn.Linear(inp_size, hidden_size))\n",
    "    layer_list.append(nn.ReLU())\n",
    "    for i in range(N-1):\n",
    "        layer_list.append(nn.Linear(hidden_size, hidden_size))\n",
    "        layer_list.append(nn.ReLU())\n",
    "    layer_list.append(nn.Linear(hidden_size, out_size))\n",
    "    return nn.Sequential(*layer_list)\n",
    "\n",
    "def get_conv_subnet(N, inp_size, kernel = 3, stride = 1):\n",
    "    layer_list = []\n",
    "    for i in range(N-1):\n",
    "        layer_list.append(nn.Conv1d(inp_size, inp_size, kernel, stride, groups = inp_size))\n",
    "        layer_list.append(nn.ReLU())\n",
    "    layer_list.append(nn.Conv1d(inp_size, inp_size, kernel, stride, groups = inp_size))\n",
    "    return nn.Sequential(*layer_list)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"\"\n",
    "    combination of convolutions and recurrent nets, used to treat the condition for our cINN beforehand.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, inp_size, hidden_size = 64, num_rnns = 5, lr = 1e-3):\n",
    "        super(RNN, self).__init__()\n",
    "        self.inp_size = inp_size\n",
    "        #self.conv = get_conv_subnet(num_conv, inp_size).to(device)\n",
    "        self.rnn = nn.LSTM(inp_size, hidden_size, num_rnns, batch_first = True, bidirectional = True).to(device)\n",
    "        #self.linear = get_linear_subnet(num_linear, hidden_size*10*2, hidden_size, out_size).to(device)\n",
    "        self.params_trainable = list(filter(\n",
    "                lambda p: p.requires_grad, self.rnn.parameters())) \n",
    "        n_trainable = sum(p.numel() for p in self.params_trainable)\n",
    "        print(f\"Number of RNN parameters: {n_trainable}\", flush=True)        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "                self.params_trainable,\n",
    "                lr = lr,\n",
    "                betas =[0.9, 0.99],\n",
    "                eps = 1e-6,\n",
    "                weight_decay = 0\n",
    "            )\n",
    "        self.scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "            )        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        full, (last, cn) = self.rnn(x)\n",
    "        return torch.swapaxes(last, 0, 1).reshape(last.shape[1], -1)\n",
    "    \n",
    "    def get_dim(self):\n",
    "        return self.forward(torch.randn(1,100,self.inp_size, device = device)).shape[1]\n",
    "        \n",
    "    \n",
    "class cINN(nn.Module):\n",
    "    \"\"\"\n",
    "    cINN baseclass, using cubic spline blocks.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, inp_size, cond_size, num_blocks = 15, sub_layers = 3, sub_width = 128, lr = 5e-3):\n",
    "        super(cINN, self).__init__()\n",
    "        constructor_fct = lambda x_in, x_out: get_linear_subnet(sub_layers, \n",
    "                                                                x_in,\n",
    "                                                                x_in,\n",
    "                                                                x_out)\n",
    "\n",
    "        block_kwargs = {\n",
    "                        \"num_bins\": 60,\n",
    "                        \"subnet_constructor\": constructor_fct,\n",
    "                        \"bounds_init\": 10,\n",
    "                        \"permute_soft\": True\n",
    "                           }\n",
    "        inp_size = (inp_size,)        \n",
    "        nodes = [InputNode(*inp_size, name='inp')]\n",
    "        cond_node = ConditionNode(*(cond_size,))\n",
    "        for i in range(num_blocks):\n",
    "            nodes.append(Node(\n",
    "                    [nodes[-1].out0],\n",
    "                    CubicSplineBlock,\n",
    "                    block_kwargs,\n",
    "                    conditions = cond_node,\n",
    "                    name = f\"block_{i}\",\n",
    "                    \n",
    "                ))\n",
    "        nodes.append(OutputNode([nodes[-1].out0], name='out'))\n",
    "        nodes.append(cond_node)\n",
    "        self.model = GraphINN(nodes, verbose=False).to(device)\n",
    "        self.params_trainable = list(filter(\n",
    "                lambda p: p.requires_grad, self.model.parameters()))\n",
    "        n_trainable = sum(p.numel() for p in self.params_trainable)\n",
    "        print(f\"Number of cINN parameters: {n_trainable}\", flush=True)\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "                self.params_trainable,\n",
    "                lr = lr,\n",
    "                betas =[0.9, 0.99],\n",
    "                eps = 1e-6,\n",
    "                weight_decay = 0\n",
    "            )\n",
    "        self.scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                verbose = True\n",
    "            )\n",
    "    def forward(self, x, cond = None):\n",
    "        return self.model(x, c = cond)\n",
    "    \n",
    "class Estimator():\n",
    "    \"\"\"\n",
    "    Wrapper for training cINN and RNN at the same time\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn, cinn):\n",
    "        self.cinn = cinn\n",
    "        self.rnn = rnn\n",
    "    def train(self, epochs, xtrain, ytrain, length, batch_size):\n",
    "        loss_curve = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_index = np.random.permutation(len(xtrain))\n",
    "            epoch_losses = 0\n",
    "            for i in range(len(xtrain)//batch_size):\n",
    "                ysamps = nn.utils.rnn.pack_padded_sequence(ytrain[i*batch_size:(i+1)*batch_size], length[i*batch_size:(i+1)*batch_size], batch_first = True, enforce_sorted = False)\n",
    "                xsamps = xtrain[i*batch_size:(i+1)*batch_size]\n",
    "                self.cinn.optimizer.zero_grad()\n",
    "                self.rnn.optimizer.zero_grad()\n",
    "                cond = self.rnn(ysamps)\n",
    "                gauss, jac = self.cinn(xsamps, cond)\n",
    "                latent_loss = torch.mean(gauss**2/2) - torch.mean(jac)/gauss.shape[1]\n",
    "                if latent_loss < 1e30:\n",
    "                    latent_loss.backward()\n",
    "                else:\n",
    "                    print(f\"loss is {latent_loss}\")\n",
    "                    return\n",
    "                self.cinn.optimizer.step()\n",
    "                self.rnn.optimizer.step()\n",
    "                epoch_losses += latent_loss.item()/(len(xtrain)//batch_size)\n",
    "            loss_curve.append(epoch_losses)\n",
    "            self.cinn.scheduler.step(epoch_losses)\n",
    "            self.rnn.scheduler.step(epoch_losses)\n",
    "            print(\"Epoch:\", epoch + 1)\n",
    "            print(\"Loss:\", epoch_losses)\n",
    "        plt.plot(np.arange(len(loss_curve)),np.array(loss_curve))\n",
    "        \n",
    "    def inference(self, data_point, true_param):  #plot parameter estimates for a time series and the true param\n",
    "        outputs = []\n",
    "        for i in range(200):\n",
    "            gauss = torch.randn(100,7).to(device)\n",
    "            cond = self.rnn(data_point.repeat(100,1,1))\n",
    "            output, _ = self.cinn(gauss, cond)\n",
    "            outputs.append(output.detach().cpu())\n",
    "        output = torch.cat(outputs, dim = 0)\n",
    "        #output = torch.tanh(output)*maximal*stds.cpu()+means.cpu()\n",
    "        fig, axis = plt.subplots(4,2, figsize = (10,15))\n",
    "        axis[0,0].hist(output.numpy()[:,0], bins = 100, density = True)\n",
    "        get_line(axis[0,0], true_param[0])\n",
    "        axis[0,0].set_title(\"initial infected\")\n",
    "        axis[0,1].hist(output.numpy()[:,1], bins = 100, density = True)\n",
    "        get_line(axis[0,1], true_param[1])\n",
    "        axis[0,1].set_title(\"populations size\")\n",
    "        axis[1,0].hist(output.numpy()[:,2], bins = 100, density = True)\n",
    "        get_line(axis[1,0], true_param[2])\n",
    "        axis[1,0].set_title(\"contagion distance\")\n",
    "        axis[1,1].hist(output.numpy()[:,3], bins = 100, density = True)\n",
    "        get_line(axis[1,1], true_param[3])\n",
    "        axis[1,1].set_title(\"critical_limit\")\n",
    "        axis[2,0].hist(output.numpy()[:,4], bins = 100, density = True)\n",
    "        get_line(axis[2,0], true_param[4])\n",
    "        axis[2,0].set_title(\"amp_susc\")\n",
    "        axis[2,1].hist(output.numpy()[:,5], bins = 100, density = True)\n",
    "        get_line(axis[2,1], true_param[5])\n",
    "        axis[2,1].set_title(\"amp_rec\")\n",
    "        axis[3,0].hist(output.numpy()[:,6], bins = 100, density = True)\n",
    "        get_line(axis[3,0], true_param[6])\n",
    "        axis[3,0].set_title(\"amp_inf\")\n",
    "        \n",
    "def get_line(ax, x):\n",
    "    ax.axvline(x, color = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RNN parameters: 434688\n",
      "Number of cINN parameters: 22233150\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Node 'block_2': [(7,)] -> CubicSplineBlock -> [(7,)] encountered an error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/covid-INN/FrEIA/framework/graph_inn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_or_z, c, rev, jac, intermediate_outputs, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                     \u001b[0mmod_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m~/Desktop/covid-INN/FrEIA/modules/spline_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, c, rev, jac)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_bins\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unconstrained_cubic_spline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/covid-INN/FrEIA/modules/spline_blocks.py\u001b[0m in \u001b[0;36m_unconstrained_cubic_spline\u001b[0;34m(self, inputs, theta, rev)\u001b[0m\n\u001b[1;32m    146\u001b[0m         min_something_2 = (\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mslopes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwidths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mslopes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwidths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 1.95 GiB total capacity; 743.30 MiB already allocated; 1.75 MiB free; 964.00 MiB reserved in total by PyTorch)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82c6bcdb43ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcinn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-669114364270>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, xtrain, ytrain, length, batch_size)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mysamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mgauss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcinn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mlatent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlatent_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-669114364270>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m    106\u001b[0m             )\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/covid-INN/FrEIA/framework/graph_inn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_or_z, c, rev, jac, intermediate_outputs, x)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mmod_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{node} encountered an error.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_jac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Node 'block_2': [(7,)] -> CubicSplineBlock -> [(7,)] encountered an error."
     ]
    }
   ],
   "source": [
    "rnn = RNN(7)\n",
    "cinn = cINN(7, rnn.get_dim())\n",
    "\n",
    "network = Estimator(rnn, cinn)\n",
    "cond = network.train(1000, params_pre, nn.utils.rnn.pad_sequence(data, batch_first = True), length, batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "network = Estimator(rnn, cinn)\n",
    "network.inference(data[i], params[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([0, 881994, 623379, 474861, 340332, 1209080])\n",
    "eff = np.array([95, 94.9, 95., 94.3, 92.8, 94.5])* 0.01\n",
    "fact_up = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_up[i] = counts[i]/np.sum(counts[i+1:])\n",
    "    \n",
    "fact_down = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_down[i] = counts[i]*(1-eff[i])/eff[i]/np.sum(counts[i+1:])\n",
    "    \n",
    "print(fact_up)\n",
    "print(fact_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.32744786 0.30448216 0.30301784 0.2788509         inf]\n",
      "[0.         0.0175973  0.01602538 0.01831603 0.02163498        inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-99eaa6533649>:5: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  fact_up[i] = counts[i]/np.sum(counts[i+1:])\n",
      "<ipython-input-6-99eaa6533649>:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  fact_down[i] = counts[i]*(1-eff[i])/eff[i]/np.sum(counts[i+1:])\n"
     ]
    }
   ],
   "source": [
    "counts = np.array([0, 1282720, 914352, 698344, 502520, 1802110])\n",
    "eff = np.array([95, 94.9, 95., 94.3, 92.8, 94.5])* 0.01\n",
    "fact_up = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_up[i] = counts[i]/np.sum(counts[i+1:])\n",
    "    \n",
    "fact_down = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_down[i] = counts[i]*(1-eff[i])/eff[i]/np.sum(counts[i+1:])\n",
    "    \n",
    "print(fact_up)\n",
    "print(fact_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.32790265 0.30497657 0.30358042 0.27945244        inf]\n",
      "[0.         0.0175973  0.01602538 0.01831603 0.02163498        inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e0f543e7ffab>:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  fact_up[i] = (counts[i]+np.sqrt(counts[i]))/(np.sum(counts[i+1:])-np.sqrt(np.sum(counts[i+1:])))\n",
      "<ipython-input-4-e0f543e7ffab>:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  fact_down[i] = counts[i]*(1-eff[i])/eff[i]/np.sum(counts[i+1:])\n"
     ]
    }
   ],
   "source": [
    "counts = np.array([0, 1282720, 914352, 698344, 502520, 1802110])\n",
    "eff = np.array([95, 94.9, 95., 94.3, 92.8, 94.5])* 0.01\n",
    "fact_up = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_up[i] = (counts[i]+np.sqrt(counts[i]))/(np.sum(counts[i+1:])-np.sqrt(np.sum(counts[i+1:])))\n",
    "    \n",
    "fact_down = np.zeros(6)\n",
    "for i in range(6):\n",
    "    fact_down[i] = counts[i]*(1-eff[i])/eff[i]/np.sum(counts[i+1:])\n",
    "    \n",
    "print(fact_up)\n",
    "print(fact_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
